{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Techniques to convert KGC in plain text\n",
    "\n",
    "We will follow [From Discrimination to Generation: Knowledge Graph Completion with Generative Transformer](https://arxiv.org/pdf/2202.02113.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "from src.utils import load_fb15k237, load_wn18rr, get_hist\n",
    "\n",
    "PATH_FB15k237 = \"data/datasets_knowledge_embedding/FB15k-237\"\n",
    "\n",
    "train, valid, test, entity2wikidata = load_fb15k237(PATH_FB15k237)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data without entity description\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.mode.copy_on_write = True\n",
    "\n",
    "all_data_fb = pd.concat([train, valid, test], axis=0)\n",
    "\n",
    "df_entity = pd.DataFrame(entity2wikidata.keys(), columns=[\"head\"])\n",
    "\n",
    "all_data_fb_filtered = all_data_fb[\n",
    "    all_data_fb[\"head\"].isin(df_entity[\"head\"])\n",
    "    & all_data_fb[\"tail\"].isin(df_entity[\"head\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_relation_to_text(relation):\n",
    "    return \"has \" + relation.split(\"/\")[-1].replace(\"_\", \" \") + \" of\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_fb_filtered[\"head_text\"] = all_data_fb_filtered[\"head\"].apply(\n",
    "    lambda i: entity2wikidata[i][\"label\"]\n",
    ")\n",
    "all_data_fb_filtered[\"relation_text\"] = all_data_fb_filtered[\"relation\"].apply(\n",
    "    lambda i: map_relation_to_text(i)\n",
    ")\n",
    "all_data_fb_filtered[\"tail_text\"] = all_data_fb_filtered[\"tail\"].apply(\n",
    "    lambda i: entity2wikidata[i][\"label\"]\n",
    ")\n",
    "\n",
    "all_data_fb_filtered[\"text\"] = (\n",
    "    all_data_fb_filtered[\"head_text\"]\n",
    "    + \" \"\n",
    "    + all_data_fb_filtered[\"relation_text\"]\n",
    "    + \" \"\n",
    "    + all_data_fb_filtered[\"tail_text\"]\n",
    "    + \".\"\n",
    ")\n",
    "\n",
    "all_data_fb_filtered[\"id\"] = all_data_fb_filtered.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_fb_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correction of \"has\" without space.\n",
    "import pandas as pd\n",
    "\n",
    "PATH_FB15k237 = \"data/datasets_knowledge_embedding/FB15k-237\"\n",
    "\n",
    "processed_data = pd.read_csv(PATH_FB15k237 + \"/processed_data.csv\")\n",
    "\n",
    "all_data_fb_filtered = processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "def train_demonstration_generator(row):\n",
    "    # select 2 samples of rows with same relation.\n",
    "    # generate triple of select rows\n",
    "    # contat triples and return\n",
    "\n",
    "    # other heuristic is split all relations e groups of 3 and use 2 for demonstration 1 to fill\n",
    "\n",
    "    \n",
    "    to_fill = row.head_text + \" \" + row.relation_text + \" \"\n",
    "    return \" \".join(\n",
    "        all_data_fb_filtered[\n",
    "            (all_data_fb_filtered[\"relation\"] == row.relation)\n",
    "            & (all_data_fb_filtered[\"id\"] != row.id)\n",
    "        ]\n",
    "        .sample(2, random_state=42)[\"text\"]\n",
    "        .to_list()\n",
    "        + [to_fill]\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import swifter\n",
    "\n",
    "all_data_fb_filtered[\"demonstration_input\"] = all_data_fb_filtered.swifter.apply(\n",
    "    lambda row: train_demonstration_generator(row), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_fb_filtered.to_csv(\n",
    "    \"data/datasets_knowledge_embedding/FB15k-237/processed_data_v2.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"data/datasets_knowledge_embedding/FB15k-237/processed_data_v2.csv\").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
